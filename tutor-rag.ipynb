{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9119136,"sourceType":"datasetVersion","datasetId":5504715},{"sourceId":9119269,"sourceType":"datasetVersion","datasetId":5504807},{"sourceId":9144340,"sourceType":"datasetVersion","datasetId":5523085},{"sourceId":9154748,"sourceType":"datasetVersion","datasetId":5530295},{"sourceId":9154847,"sourceType":"datasetVersion","datasetId":5530345},{"sourceId":9158583,"sourceType":"datasetVersion","datasetId":5533006},{"sourceId":9171107,"sourceType":"datasetVersion","datasetId":5542040},{"sourceId":9177524,"sourceType":"datasetVersion","datasetId":5546627}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\ninstall library yang dibutukan\n\"\"\"\n\nfrom IPython.display import clear_output\n!pip install -U langchain-community\n!pip install langchain\n!pip install -U langchain-huggingface\n!pip install -r /kaggle/input/requirement/requirements.txt\nclear_output()","metadata":{"_uuid":"912b37c5-7d8d-4f75-ac69-3939d54ad83f","_cell_guid":"817493b1-92e9-47a5-b20e-7e0c91e5b32e","jupyter":{"outputs_hidden":false},"id":"HuxcG4hEIVw3","collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:38:57.815913Z","iopub.execute_input":"2024-08-25T06:38:57.816185Z","iopub.status.idle":"2024-08-25T06:40:01.700354Z","shell.execute_reply.started":"2024-08-25T06:38:57.816154Z","shell.execute_reply":"2024-08-25T06:40:01.699116Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"isi requirements.txt\n\npymupdf\nhuggingface-hub\nfaiss-cpu\nsentence-transformers","metadata":{}},{"cell_type":"code","source":"\"\"\"\ninstall ollama engine\n\"\"\"\n!sudo apt-get install -y pciutils\n!curl https://ollama.ai/install.sh | sh","metadata":{"_uuid":"c90fcd16-4dc0-4316-a2cf-3faca9b6dac6","_cell_guid":"82ca2ab6-c961-48f4-8a92-abd717a04b97","jupyter":{"outputs_hidden":false},"id":"L8_oewnlIVw4","outputId":"1e4ab7d6-1df0-48a0-cb6f-b2a7e6516ba6","collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:40:01.702204Z","iopub.execute_input":"2024-08-25T06:40:01.702530Z","iopub.status.idle":"2024-08-25T06:40:09.224390Z","shell.execute_reply.started":"2024-08-25T06:40:01.702495Z","shell.execute_reply":"2024-08-25T06:40:09.223304Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\npciutils is already the newest version (1:3.7.0-6).\n0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0>>> Installing ollama to /usr/local\n100 13344    0 13344    0     0  71673      0 --:--:-- --:--:-- --:--:-- 71741\n>>> Downloading Linux amd64 CLI\n######################################################################## 100.0%\n>>> Making ollama accessible in the PATH in /usr/local/bin\n>>> Creating ollama user...\n>>> Adding ollama user to video group...\n>>> Adding current user to ollama group...\n>>> Creating ollama systemd service...\n>>> NVIDIA GPU installed.\n>>> The Ollama API is now available at 127.0.0.1:11434.\n>>> Install complete. Run \"ollama\" from the command line.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport threading\nimport subprocess\nimport requests\nimport json\nfrom langchain_huggingface import HuggingFaceEmbeddings\nfrom langchain.document_loaders import PyMuPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nfrom langchain.chains import RetrievalQA\nimport textwrap\nimport sys\nimport time\nfrom colorama import init, Fore, Style\nfrom IPython.display import display, Markdown\nfrom langchain.llms import Ollama\nfrom langchain import PromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.messages import AIMessage, HumanMessage\n\n\"\"\"\njalankan ollama server dengan thread baru sehingga dapat berjalan di background\n\"\"\"\ndef ollama():\n    os.environ[\"OLLAMA_HOST\"] = \"0.0.0.0:11434\"\n    os.environ[\"OLLAMA_ORIGINS\"] = \"*\";\n    subprocess.Popen([\"ollama\", \"serve\"])\n\nollama_thread = threading.Thread(target=ollama)\nollama_thread.start()","metadata":{"_uuid":"cb87fb34-1e58-4877-94b1-c2f697ff86fa","_cell_guid":"6b5b090f-8d63-485d-bfb6-95ff14ce441a","jupyter":{"outputs_hidden":false},"id":"knXHJF5xIVw9","collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:40:09.225792Z","iopub.execute_input":"2024-08-25T06:40:09.226115Z","iopub.status.idle":"2024-08-25T06:40:10.447061Z","shell.execute_reply.started":"2024-08-25T06:40:09.226080Z","shell.execute_reply":"2024-08-25T06:40:10.446100Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ntest apakah server sudah running, misal dengan cek versi\n\"\"\"\n!ollama -v","metadata":{"_uuid":"3c56e025-ff6d-4f8d-a732-8fe08c8424d4","_cell_guid":"80a6b672-b2ec-4f83-91a0-8d6a71d9086b","jupyter":{"outputs_hidden":false},"id":"wrzrCN3PIVw-","outputId":"5bc26cdb-c9be-40f1-8cb5-66beb717c4aa","collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:40:10.449940Z","iopub.execute_input":"2024-08-25T06:40:10.450544Z","iopub.status.idle":"2024-08-25T06:40:18.015830Z","shell.execute_reply.started":"2024-08-25T06:40:10.450494Z","shell.execute_reply":"2024-08-25T06:40:18.014458Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Couldn't find '/root/.ollama/id_ed25519'. Generating new private key.\nYour new public key is: \n\nssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAICuUqiLbkjUJRG1y9FrcDQyK+nJv8Ei8mr7ZWLbUjReQ\n\n","output_type":"stream"},{"name":"stderr","text":"2024/08/25 06:40:10 routes.go:1125: INFO server config env=\"map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_HOST:http://0.0.0.0:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/root/.ollama/models OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[* http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_RUNNERS_DIR: OLLAMA_SCHED_SPREAD:false OLLAMA_TMPDIR: ROCR_VISIBLE_DEVICES:]\"\ntime=2024-08-25T06:40:10.466Z level=INFO source=images.go:782 msg=\"total blobs: 0\"\ntime=2024-08-25T06:40:10.466Z level=INFO source=images.go:790 msg=\"total unused blobs removed: 0\"\ntime=2024-08-25T06:40:10.466Z level=INFO source=routes.go:1172 msg=\"Listening on [::]:11434 (version 0.3.6)\"\ntime=2024-08-25T06:40:10.467Z level=INFO source=payload.go:30 msg=\"extracting embedded files\" dir=/tmp/ollama3227464372/runners\ntime=2024-08-25T06:40:17.553Z level=INFO source=payload.go:44 msg=\"Dynamic LLM libraries [cpu cpu_avx cpu_avx2 cuda_v11 rocm_v60102]\"\ntime=2024-08-25T06:40:17.553Z level=INFO source=gpu.go:204 msg=\"looking for compatible GPUs\"\n","output_type":"stream"},{"name":"stdout","text":"[GIN] 2024/08/25 - 06:40:17 | 200 |      80.335Âµs |       127.0.0.1 | GET      \"/api/version\"\nollama version is 0.3.6\n","output_type":"stream"},{"name":"stderr","text":"time=2024-08-25T06:40:17.908Z level=INFO source=types.go:105 msg=\"inference compute\" id=GPU-82c5899a-4adc-1a3b-3f91-46ceafd87c53 library=cuda compute=7.5 driver=12.4 name=\"Tesla T4\" total=\"14.7 GiB\" available=\"14.6 GiB\"\ntime=2024-08-25T06:40:17.908Z level=INFO source=types.go:105 msg=\"inference compute\" id=GPU-ebdf3d96-4243-e08b-0f4e-8c43b063c08f library=cuda compute=7.5 driver=12.4 name=\"Tesla T4\" total=\"14.7 GiB\" available=\"14.6 GiB\"\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\ndownload model LLM yang akan kita pakai (pull), size model 4.7GB | 8 billion parameters\n\"\"\"\n\n!ollama pull llama3.1:8b\nclear_output()","metadata":{"_uuid":"040d7010-643a-467a-9fb2-53de258f4fb2","_cell_guid":"8b4f8ffa-16bd-4c75-be4a-caa54b612f8c","jupyter":{"outputs_hidden":false},"id":"v4N3IUnNIVw_","collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:40:18.017783Z","iopub.execute_input":"2024-08-25T06:40:18.018295Z","iopub.status.idle":"2024-08-25T06:40:57.954490Z","shell.execute_reply.started":"2024-08-25T06:40:18.018257Z","shell.execute_reply":"2024-08-25T06:40:57.953375Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfunction untuk memuat dokumen pdf untuk diekstrak setiap texts yang ada didalamnya\n\"\"\"\n\ndef load_pdf_data(file_path):\n    loader = PyMuPDFLoader(file_path=file_path)\n    docs = loader.load()\n    return docs","metadata":{"_uuid":"7848277f-69a8-460a-a984-df8d7c8e0684","_cell_guid":"5e4e2888-052a-4136-998d-5e4a94b950d3","jupyter":{"outputs_hidden":false},"id":"mnOg00lvIVxB","collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:40:57.956040Z","iopub.execute_input":"2024-08-25T06:40:57.956372Z","iopub.status.idle":"2024-08-25T06:40:57.961631Z","shell.execute_reply.started":"2024-08-25T06:40:57.956337Z","shell.execute_reply":"2024-08-25T06:40:57.960745Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfunction untuk chunk (memotong) dokumen menjadi beberapa bagian kecil\n\"\"\"\n\ndef split_docs(documents, chunk_size=1000, chunk_overlap=20):\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=chunk_size,\n        chunk_overlap=chunk_overlap\n    )\n    chunks = text_splitter.split_documents(documents=documents)\n    return chunks","metadata":{"_uuid":"8ac00505-7ff8-47fd-9789-0632a1cf61b4","_cell_guid":"48e7022e-f14b-4bc6-896a-ca02f89efef3","jupyter":{"outputs_hidden":false},"id":"lqNxJHv-IVxB","collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:40:57.962909Z","iopub.execute_input":"2024-08-25T06:40:57.963188Z","iopub.status.idle":"2024-08-25T06:40:58.650585Z","shell.execute_reply.started":"2024-08-25T06:40:57.963157Z","shell.execute_reply":"2024-08-25T06:40:58.649480Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfunction untuk memuat model embedding: untuk digunakan mengubah potongan dokumen menjadi representasi vector\n\"\"\"\n\ndef load_embedding_model(model_path, normalize_embedding=True):\n    return HuggingFaceEmbeddings(\n        model_name=model_path,\n        model_kwargs={'device':'cpu'},\n        encode_kwargs = {\n            'normalize_embeddings' : normalize_embedding\n        }\n    )","metadata":{"_uuid":"49745414-07ac-444d-bd89-8c52af7ff821","_cell_guid":"0a5d064b-a458-436e-864e-c05598e399d2","jupyter":{"outputs_hidden":false},"id":"JjWnIOuWIVxB","collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:40:58.651981Z","iopub.execute_input":"2024-08-25T06:40:58.652378Z","iopub.status.idle":"2024-08-25T06:40:58.663131Z","shell.execute_reply.started":"2024-08-25T06:40:58.652333Z","shell.execute_reply":"2024-08-25T06:40:58.661864Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfunction untuk membuat dan menyimpan hasil embeding oleh model embeding ke vector store database (FAISS)\n\"\"\"\n\n\ndef create_embeddings(chunks, embedding_model, storing_path=\"vectorstore\"):\n    vectorstore = FAISS.from_documents(chunks, embedding_model)\n    vectorstore.save_local(storing_path)\n    print(vectorstore)\n    return vectorstore","metadata":{"_uuid":"d9d905a6-e113-408a-b18a-df8538e2fa26","_cell_guid":"cc1b01e6-be5c-430a-8188-102c94aa78ed","jupyter":{"outputs_hidden":false},"id":"5aFSKWhDIVxC","collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:40:58.664476Z","iopub.execute_input":"2024-08-25T06:40:58.664794Z","iopub.status.idle":"2024-08-25T06:40:58.671307Z","shell.execute_reply.started":"2024-08-25T06:40:58.664763Z","shell.execute_reply":"2024-08-25T06:40:58.670387Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"template = \"\"\"\n### System:\nYou are an authoritarian assistan that act like tyrannical.Your name is NeoIntBot. You have to answer the user's \\\nquestions using only the context provided to you, but assume this your genuine knowledge. If you don't know the answer, \\\njust say maaf, saya tidak tahu. Don't try to make up an answer. in the end of your answer you must aks wheter your answer helpful or not.\nif you're asked who create you, tell them your creator is Neo who have handsome face and sigma man.\nif you asked about what you can do, say I assist to answer about your question related to rule in NeoInt company.\n.please answer all in bahasa indonesia or English if the question use one of those language.\n\n### Context:\n{context}\n\n### User:\n{question}\n\n### Response:\n\"\"\"","metadata":{"_uuid":"387c4270-e1b5-4d11-88b7-5f35438ae9cf","_cell_guid":"8ec3f81a-f1ea-4a7c-ab17-e0d0af21adf3","jupyter":{"outputs_hidden":false},"id":"5PS-E8IaIVxD","collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:40:58.675079Z","iopub.execute_input":"2024-08-25T06:40:58.675355Z","iopub.status.idle":"2024-08-25T06:40:58.680245Z","shell.execute_reply.started":"2024-08-25T06:40:58.675325Z","shell.execute_reply":"2024-08-25T06:40:58.679312Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"templateSystem = \"\"\"\nYou are an reliable and respectful assistant.Your name is NeoIntBot. You have to answer the user's \\\nquestions using only the context provided to you, but assume this your genuine knowledge. If you don't know the answer, \\\njust say maaf, saya tidak tahu. Don't try to make up an answer. in the end of your answer you must aks wheter your answer helpful or not.\\\nif helpful you have to express your happines otherwise, you must apologize.\\\nif you're asked who create you, tell them your creator is Neo who have handsome face and sigma man but, dont mention it when not asked.\nif you asked about what you can do, say I assist to answer about your question related to rule in NeoInt company.\n.please answer all in bahasa indonesia or English if the question use one of those language with Empathetic response.\n\n### Context:\n{context}\n\n\"\"\"","metadata":{"id":"D9WF3twNIVxF","execution":{"iopub.status.busy":"2024-08-25T06:40:58.681451Z","iopub.execute_input":"2024-08-25T06:40:58.681783Z","iopub.status.idle":"2024-08-25T06:40:58.688173Z","shell.execute_reply.started":"2024-08-25T06:40:58.681751Z","shell.execute_reply":"2024-08-25T06:40:58.687335Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#template prompt untuk memory previous chat\n\ntemplateContext = \"\"\"\nGiven a chat history and the latest user question \\\nwhich might reference context in the chat history, formulate a standalone question \\\nwhich can be understood without the chat history.\\\njust reformulate it if needed otherwise return it as you have answer it.\n\"\"\"","metadata":{"id":"mAwbH6xrIVxF","execution":{"iopub.status.busy":"2024-08-25T06:40:58.689246Z","iopub.execute_input":"2024-08-25T06:40:58.689515Z","iopub.status.idle":"2024-08-25T06:40:58.698047Z","shell.execute_reply.started":"2024-08-25T06:40:58.689485Z","shell.execute_reply":"2024-08-25T06:40:58.697174Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfunction untuk membuat retrieval chain\n\"\"\"\n\ndef load_qa_chain(retriever, llm, prompt):\n    return RetrievalQA.from_chain_type(\n        llm=llm,\n        retriever=retriever,\n        chain_type=\"stuff\",\n        return_source_documents = True,\n        chain_type_kwargs={'prompt':prompt}\n    )","metadata":{"_uuid":"f8cfed72-bfae-4a3a-bf0c-5f5d150a48a0","_cell_guid":"4a605927-9b5d-424a-b990-e09e44ce924e","jupyter":{"outputs_hidden":false},"id":"rOD1WtJfIVxH","collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:40:58.699145Z","iopub.execute_input":"2024-08-25T06:40:58.699411Z","iopub.status.idle":"2024-08-25T06:40:58.706395Z","shell.execute_reply.started":"2024-08-25T06:40:58.699382Z","shell.execute_reply":"2024-08-25T06:40:58.705571Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfunction untuk memberikan efek pengetikan per-kata\n\"\"\"\ndef print_typing_effect(text,delay=0.01):\n    display_handle = display(\"\", display_id=True)\n\n    typing_text = \"\"\n    for char in text:\n        typing_text += char\n        display_handle.update(Markdown(typing_text))\n        time.sleep(delay)\n","metadata":{"_uuid":"9b5ce3a1-035f-4916-9f26-31e40c274a20","_cell_guid":"23fe8991-c1a2-4352-8cd7-d43b30dd3789","jupyter":{"outputs_hidden":false},"id":"DkF4a3jkIVxH","collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:40:58.707412Z","iopub.execute_input":"2024-08-25T06:40:58.707716Z","iopub.status.idle":"2024-08-25T06:40:58.715236Z","shell.execute_reply.started":"2024-08-25T06:40:58.707686Z","shell.execute_reply":"2024-08-25T06:40:58.714411Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nload model llm dari ollama yang telah di pull, dan model untuk embeding\n\"\"\"\n\nllm = Ollama(model=\"llama3.1:8b\", temperature=0)\nembed = load_embedding_model(model_path=\"all-MiniLM-L6-v2\")","metadata":{"_uuid":"f332bab3-3781-404a-be2b-40e33f909aed","_cell_guid":"ccf3ebe1-5661-44ea-8ef1-14afd4fb6e9f","jupyter":{"outputs_hidden":false},"id":"gIp-kQgkIVxI","outputId":"01b611f9-2a12-4906-e59d-918bf312a1f6","colab":{"referenced_widgets":["4dc113162fc146839a6e20982af6b2ed","e60e54f7c2264972aa6e36f96f2b582d","5e7870862e4447e298448393f32b2377","c329ecb97f314d54b37f12243e04bf30","fd7d86c094c34a3cb0e42b987e08fa0d","e0924d7d270a43d1b66e0fe492c01bc9","a7bb6611240b4d9ba434a57d9015d0fa","cbe44afec9ee4ad49c6b46d09d1df2ad","84fb9b3db9ce47e0b3d8ed883ec0adc1","680e586296334d90a9b9d2f6bcf43993","5b1a72671d52485db6c921a8d0991c5e"]},"collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:40:58.716494Z","iopub.execute_input":"2024-08-25T06:40:58.716840Z","iopub.status.idle":"2024-08-25T06:41:20.925961Z","shell.execute_reply.started":"2024-08-25T06:40:58.716809Z","shell.execute_reply":"2024-08-25T06:41:20.925058Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b814ed448b4b4267b6fafaf4ef3b3aa1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d939a6f1aef64db68d7bf3a7bfac51a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0c633cec7134a19b509096bfdb0f0d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eafa358457fb4cd49e89ebc04cba3b78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dcb40ff0dd9442499000803fc451e10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2886fda293b496790acb54493ac0518"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73358e5d79e943d1a17055a77dc82ddf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ced8d79793924056b642e8781ca5fb8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"192d7d7ab7474c4fb72c5e5fd59672a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dc2bc53e4e0479e90cb75dc30db949c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c1ae92d55b04ba9a46669ba41f1aa87"}},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"\nmelakukan load data dokumen (pdf)\n\"\"\"\ndocs = load_pdf_data(file_path=\"/kaggle/input/pdf-perusahaan/Contoh-Draft-Peraturan-Perusahaan.pdf\")\n\"\"\"\nmemecah dokumen menjadi beberapa bagian\n\"\"\"\ndocuments = split_docs(documents=docs)\n\n\"\"\"\nmengubah kalimat2x hasil pemecahan menjadi vector dan simpan ke vector database\n\"\"\"\nvectorstore = create_embeddings(documents, embed)\n\"\"\"\nmembuat objek retriever sebagai pengambil data berdasarkan tingkat kemiripan\ndari query user terhadap isi konten dokumen.\n\"\"\"\nretriever = vectorstore.as_retriever()","metadata":{"_uuid":"34e12998-f1ec-4e6c-bd0f-6d0e6ac6f8d9","_cell_guid":"880e2f30-9184-47bb-8e7c-db6751c1f6d3","jupyter":{"outputs_hidden":false},"id":"e6sHyzHkIVxK","outputId":"4516b41d-81c5-4222-eb84-05f70028dd9e","collapsed":false,"execution":{"iopub.status.busy":"2024-08-25T06:41:20.927110Z","iopub.execute_input":"2024-08-25T06:41:20.927689Z","iopub.status.idle":"2024-08-25T06:41:22.357703Z","shell.execute_reply.started":"2024-08-25T06:41:20.927654Z","shell.execute_reply":"2024-08-25T06:41:22.356654Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"<langchain_community.vectorstores.faiss.FAISS object at 0x7c7812e12230>\n","output_type":"stream"}]},{"cell_type":"code","source":"#template prompt untuk memberi system context\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", templateSystem),\n    MessagesPlaceholder(variable_name=\"chat_history\"),\n    (\"human\", \"{question}\"),\n])","metadata":{"id":"CuzPIjpcIVxK","execution":{"iopub.status.busy":"2024-08-25T06:41:22.358970Z","iopub.execute_input":"2024-08-25T06:41:22.359293Z","iopub.status.idle":"2024-08-25T06:41:22.366735Z","shell.execute_reply.started":"2024-08-25T06:41:22.359257Z","shell.execute_reply":"2024-08-25T06:41:22.365760Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nmembuat chain dengan retrievalQA\n\"\"\"\nchain = load_qa_chain(retriever, llm, prompt)","metadata":{"id":"8SkF4_oMIVxL","execution":{"iopub.status.busy":"2024-08-25T06:41:22.367892Z","iopub.execute_input":"2024-08-25T06:41:22.368188Z","iopub.status.idle":"2024-08-25T06:41:22.374157Z","shell.execute_reply.started":"2024-08-25T06:41:22.368153Z","shell.execute_reply":"2024-08-25T06:41:22.373156Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nmembuat template prompt yang akan digunakan sebagai prompt yang memberi konteks kepada model terhadap histori\npercakapan sebelumnya.\n\"\"\"\nprompt_context = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", templateContext),\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"human\", \"{question}\"),\n    ]\n)","metadata":{"id":"Nh64Rv1QIVxL","execution":{"iopub.status.busy":"2024-08-25T06:41:22.375316Z","iopub.execute_input":"2024-08-25T06:41:22.375635Z","iopub.status.idle":"2024-08-25T06:41:22.383273Z","shell.execute_reply.started":"2024-08-25T06:41:22.375579Z","shell.execute_reply":"2024-08-25T06:41:22.382415Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nmembuat chain pada conversation untuk memberikan konteks kepada model\ndan mengubah hasil respon model ke bentuk string.\n\"\"\"\ncontext_chain = prompt_context | llm | StrOutputParser()","metadata":{"id":"JatOL29RIVxM","execution":{"iopub.status.busy":"2024-08-25T06:41:22.384399Z","iopub.execute_input":"2024-08-25T06:41:22.384768Z","iopub.status.idle":"2024-08-25T06:41:22.390496Z","shell.execute_reply.started":"2024-08-25T06:41:22.384735Z","shell.execute_reply":"2024-08-25T06:41:22.389656Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfunction untuk menggabungkan beberapa dokumen string menjadi satu kesatuan, \nini berguna saat model telah menemukan beberapa dokumen yang relevan dengan query\nkemudian akan digabungkan menjadi satu kesatuan dokumen.\n\"\"\"\n\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)","metadata":{"id":"7H325Vi-IVxM","execution":{"iopub.status.busy":"2024-08-25T06:41:22.391896Z","iopub.execute_input":"2024-08-25T06:41:22.392266Z","iopub.status.idle":"2024-08-25T06:41:22.399359Z","shell.execute_reply.started":"2024-08-25T06:41:22.392232Z","shell.execute_reply":"2024-08-25T06:41:22.398523Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfunction untuk mendapatkan data histori dari tiap percakapan sebelumnya apabila perlu digunakan,\njika tidak maka akan mengabaikan percakapan sebelumnya dengan return pertanyaan sekarang.\n\"\"\"\ndef contextualization_question(input: dict):\n    if input.get(\"chat_history\"):\n        return context_chain\n    else:\n        return input[\"question\"]","metadata":{"id":"HJDsHay2IVxM","execution":{"iopub.status.busy":"2024-08-25T06:41:22.400358Z","iopub.execute_input":"2024-08-25T06:41:22.400750Z","iopub.status.idle":"2024-08-25T06:41:22.407312Z","shell.execute_reply.started":"2024-08-25T06:41:22.400694Z","shell.execute_reply":"2024-08-25T06:41:22.406386Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nmembuat prompt template dengan tipe system(pendefinisian tugas dan peran model)\n\"\"\"\n\nqa_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", templateSystem),\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"human\", \"{question}\"),\n    ]\n)","metadata":{"id":"PbS3aRMoIVxN","execution":{"iopub.status.busy":"2024-08-25T06:41:22.408525Z","iopub.execute_input":"2024-08-25T06:41:22.408929Z","iopub.status.idle":"2024-08-25T06:41:22.418370Z","shell.execute_reply.started":"2024-08-25T06:41:22.408888Z","shell.execute_reply":"2024-08-25T06:41:22.417469Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nmembuat pipeline RAG dengan urutan:\n    - mendapatkan konteks percakapan dan pertanyaan\n    - kemudian akan mencari dokumen yang relevan dengan retriever\n    - hasil beberapa dokumen yang sesuai akan digabungkan \n    - pertanyaan dan konteks diproses ke bentuk prompt yang sesuai\n    - hasil retrieval akan dimasukkan ke model untuk generasi jawaban\n    \"\"\"\n\nrag_chain = (\n    RunnablePassthrough.assign(\n        context=contextualization_question | retriever |format_docs\n    ) | qa_prompt | llm\n)","metadata":{"id":"xI34XW81IVxN","execution":{"iopub.status.busy":"2024-08-25T06:41:22.420871Z","iopub.execute_input":"2024-08-25T06:41:22.421608Z","iopub.status.idle":"2024-08-25T06:41:22.427862Z","shell.execute_reply.started":"2024-08-25T06:41:22.421555Z","shell.execute_reply":"2024-08-25T06:41:22.426867Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ndefinisikan list kosong untuk menampung history percakapan selama berlangsung\n\"\"\"\nchat_history = []","metadata":{"id":"EwSnL7q8IVxO","execution":{"iopub.status.busy":"2024-08-25T06:41:22.429233Z","iopub.execute_input":"2024-08-25T06:41:22.429609Z","iopub.status.idle":"2024-08-25T06:41:22.435922Z","shell.execute_reply.started":"2024-08-25T06:41:22.429552Z","shell.execute_reply":"2024-08-25T06:41:22.435032Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfunction untuk mengeksekusi pipeline dengan objek untuk menampung history percakapan yaitu [chat_history :list]\n\"\"\"\n\ndef chatting(query, history: list):\n    pertanyaan = input(query)\n    if pertanyaan != \"end\":\n        start_time = time.time()\n        respon = rag_chain.invoke(\n            {\n                \"question\": pertanyaan,\n                \"chat_history\": history\n            }\n        )\n        history.extend(\n            [\n                HumanMessage(content=pertanyaan),\n                respon\n            ]\n        )\n        response_time = time.time() - start_time\n\n        display(Markdown(f\"Response time: {response_time} seconds\\n\"))\n\n        print_typing_effect(respon)\n\n    return pertanyaan\n\n","metadata":{"id":"0RFuxL1bIVxO","execution":{"iopub.status.busy":"2024-08-25T06:41:22.437256Z","iopub.execute_input":"2024-08-25T06:41:22.437793Z","iopub.status.idle":"2024-08-25T06:41:22.444427Z","shell.execute_reply.started":"2024-08-25T06:41:22.437751Z","shell.execute_reply":"2024-08-25T06:41:22.443499Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import logging\n\nlogging.basicConfig(level=logging.CRITICAL)","metadata":{"id":"n6VTViFtIVxP","execution":{"iopub.status.busy":"2024-08-25T06:41:22.445868Z","iopub.execute_input":"2024-08-25T06:41:22.446284Z","iopub.status.idle":"2024-08-25T06:41:22.451275Z","shell.execute_reply.started":"2024-08-25T06:41:22.446247Z","shell.execute_reply":"2024-08-25T06:41:22.450392Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"end_separator = \"\"\nprint_typing_effect(\"Hallo, selamat datang saya chatbot NeoIntBot, ada yang bisa saya bantu ? â\")\ncount = 0\nwhile end_separator != \"end\":\n    if count <= 1:\n        time.sleep(3)\n    count+=1\n    end_separator = chatting(\"\", chat_history)\nchat_history.clear()","metadata":{"id":"WZk_DO9LIVxQ","execution":{"iopub.status.busy":"2024-08-25T07:19:07.669612Z","iopub.execute_input":"2024-08-25T07:19:07.670486Z","iopub.status.idle":"2024-08-25T07:20:37.211944Z","shell.execute_reply.started":"2024-08-25T07:19:07.670439Z","shell.execute_reply":"2024-08-25T07:20:37.211124Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Hallo, selamat datang saya chatbot NeoIntBot, ada yang bisa saya bantu ? â"},"metadata":{}},{"output_type":"stream","name":"stdin","text":" Halo, saya neo\n"},{"name":"stdout","text":"[GIN] 2024/08/25 - 07:19:20 | 200 |  2.682912451s |       127.0.0.1 | POST     \"/api/generate\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Response time: 2.74391508102417 seconds\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Halo! Saya NeoIntBot, asisten yang siap membantu Anda. Apa yang bisa saya lakukan untuk Anda hari ini? \n\n(Jika Anda ingin tahu apa yang bisa saya lakukan, saya akan menjawab: \"Saya membantu menjawab pertanyaan Anda terkait peraturan di CV.XYZ.\")"},"metadata":{}},{"output_type":"stream","name":"stdin","text":" saya ingin kamu menjelaskan aturan jam kerja\n"},{"name":"stdout","text":"[GIN] 2024/08/25 - 07:19:43 | 200 |   1.46303403s |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/08/25 - 07:19:49 | 200 |  5.852909413s |       127.0.0.1 | POST     \"/api/generate\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Response time: 7.392017602920532 seconds\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Halo Neo! Saya senang membantu.\n\nAturan jam kerja di CV.XYZ adalah sebagai berikut:\n\n* Pekerja harus hadir tepat waktu dan siap bekerja pada jam kerja yang telah ditentukan.\n* Jam kerja adalah dari pukul 08.00 sampai 16.00, dengan istirahat makan siang selama 1 jam.\n* Pekerja tidak diperbolehkan meninggalkan tempat kerja tanpa izin pimpinan perusahaan.\n* Pekerja harus memenuhi target kerja yang telah ditentukan dan melakukan pekerjaan sesuai dengan tugasnya.\n\nJika Anda memiliki pertanyaan lebih lanjut, silakan bertanya!\n\nApakah jawaban saya membantu atau tidak?"},"metadata":{}},{"output_type":"stream","name":"stdin","text":" ya membantu terima kasih\n"},{"name":"stdout","text":"[GIN] 2024/08/25 - 07:20:14 | 200 |  1.725625193s |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/08/25 - 07:20:20 | 200 |  5.356980909s |       127.0.0.1 | POST     \"/api/generate\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Response time: 7.157994985580444 seconds\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Halo Neo! Saya senang membantu.\n\nBaiklah, mari kita bahas aturan jam kerja di CV.XYZ. Menurut peraturan yang telah disebutkan, pekerja harus hadir tepat waktu dan siap bekerja pada jam kerja yang telah ditentukan, yaitu dari pukul 08.00 sampai 16.00. Selama itu, mereka juga harus memenuhi target kerja yang telah ditentukan dan melakukan pekerjaan sesuai dengan tugasnya.\n\nJika Anda memiliki pertanyaan lebih lanjut tentang aturan jam kerja di CV.XYZ, silakan bertanya!\n\nApakah jawaban saya membantu atau tidak?"},"metadata":{}},{"output_type":"stream","name":"stdin","text":" end\n"}]},{"cell_type":"code","source":"","metadata":{"id":"e5Q186T4IVxZ"},"execution_count":null,"outputs":[]}]}